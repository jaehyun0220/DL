{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Git_Temp_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwLb9EDysf0BQaS/QKS7zN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehyun0220/DL/blob/master/Git_Temp_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HXiViiEiDI3",
        "outputId": "43770733-56b8-432a-f760-7befaa7a45e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 데이터 활용에 필요한 기본 패키지 로딩\n",
        "import sys #access to system parameters \n",
        "print(\"Python version: {}\". format(sys.version))\n",
        "\n",
        "import pandas as pd\n",
        "print(\"pandas version: {}\". format(pd.__version__))\n",
        "\n",
        "import sklearn #collection of machine learning algorithms\n",
        "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
        "\n",
        "import numpy as np #foundational package for scientific computing\n",
        "print(\"NumPy version: {}\". format(np.__version__))\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"tensorflow version: {}\".format(tf.__version__))\n",
        "\n",
        "import os\n",
        "#import io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n",
            "pandas version: 1.1.5\n",
            "scikit-learn version: 0.22.2.post1\n",
            "NumPy version: 1.19.5\n",
            "tensorflow version: 2.4.1\n",
            "keras version: 2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYj3r2pO0YAw",
        "outputId": "3c3de402-9e25-485b-fc98-42ed7d4b30a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Auth 인증 및 Google Drive 활용 Data load\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "# Google Drive 내 Custom Class 경로 지정\n",
        "import sys\n",
        "sys.path.insert(0, '/gdrive/My Drive/CustomClasses')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw9-CZlf017n",
        "outputId": "91009a38-881d-43dc-e47b-e0597d15b62c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /gdrive/My\\ Drive/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert\t\t   df_all.gsheet\tjoongo.csv\t       test.csv\n",
            "chromedriver\t   download\t\tmj-clean.csv\t       train.csv\n",
            "crawl-300d-2M.vec  FashionMNIST\t\tsample_submission.csv\n",
            "df_all.csv\t   glove.840B.300d.txt\tStudy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF1V92Nr02ne"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9UcAymy03Io",
        "outputId": "1ca4e3e4-c98c-4624-f4e9-e011548c888a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"This file contains code for use with \"Think Stats\",\n",
        "by Allen B. Downey, available from greenteapress.com\n",
        "Copyright 2014 Allen B. Downey\n",
        "License: GNU GPLv3 http://www.gnu.org/licenses/gpl.html\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.tsa.stattools as smtsa\n",
        "\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "import thinkplot\n",
        "import thinkstats2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24szpueF1myd"
      },
      "source": [
        "FORMATS = ['png']\n",
        "\n",
        "def ReadData():\n",
        "    \"\"\"Reads data about cannabis transactions.\n",
        "    http://zmjones.com/static/data/mj-clean.csv\n",
        "    returns: DataFrame\n",
        "    \"\"\"\n",
        "    transactions = pd.read_csv('/gdrive/My Drive/data/mj-clean.csv', parse_dates=[5])\n",
        "    return transactions\n",
        "\n",
        "\n",
        "def tmean(series):\n",
        "    \"\"\"Computes a trimmed mean.\n",
        "    series: Series \n",
        "    returns: float\n",
        "    \"\"\"\n",
        "    t = series.values\n",
        "    n = len(t)\n",
        "    if n <= 3:\n",
        "        return t.mean()\n",
        "    trim = max(1, n//10)\n",
        "    return np.mean(sorted(t)[trim:n-trim])\n",
        "\n",
        "\n",
        "def GroupByDay(transactions, func=np.mean):\n",
        "    \"\"\"Groups transactions by day and compute the daily mean ppg.\n",
        "    transactions: DataFrame of transactions\n",
        "    returns: DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    groups = transactions[['date', 'ppg']].groupby('date')\n",
        "    daily = groups.aggregate(func)\n",
        "\n",
        "    daily['date'] = daily.index\n",
        "    start = daily.date[0]\n",
        "    one_year = np.timedelta64(1, 'Y')\n",
        "    daily['years'] = (daily.date - start) / one_year\n",
        "\n",
        "    return daily\n",
        "\n",
        "\n",
        "def GroupByQualityAndDay(transactions):\n",
        "    \"\"\"Divides transactions by quality and computes mean daily price.\n",
        "    transaction: DataFrame of transactions\n",
        "    \n",
        "    returns: map from quality to time series of ppg\n",
        "    \"\"\"\n",
        "    groups = transactions.groupby('quality')\n",
        "    dailies = {}\n",
        "    for name, group in groups:\n",
        "        dailies[name] = GroupByDay(group)        \n",
        "\n",
        "    return dailies\n",
        "\n",
        "\n",
        "def PlotDailies(dailies):\n",
        "    \"\"\"Makes a plot with daily prices for different qualities.\n",
        "    dailies: map from name to DataFrame\n",
        "    \"\"\"\n",
        "    thinkplot.PrePlot(rows=3)\n",
        "    for i, (name, daily) in enumerate(dailies.items()):\n",
        "        thinkplot.SubPlot(i+1)\n",
        "        title = 'price per gram ($)' if i == 0 else ''\n",
        "        thinkplot.Config(ylim=[0, 20], title=title)\n",
        "        thinkplot.Scatter(daily.ppg, s=10, label=name)\n",
        "        if i == 2: \n",
        "            pyplot.xticks(rotation=30)\n",
        "        else:\n",
        "            thinkplot.Config(xticks=[])\n",
        "\n",
        "    thinkplot.Save(root='timeseries1',\n",
        "                   formats=FORMATS)\n",
        "\n",
        "\n",
        "def RunLinearModel(daily):\n",
        "    \"\"\"Runs a linear model of prices versus years.\n",
        "    daily: DataFrame of daily prices\n",
        "    returns: model, results\n",
        "    \"\"\"\n",
        "    model = smf.ols('ppg ~ years', data=daily)\n",
        "    results = model.fit()\n",
        "    return model, results\n",
        "\n",
        "\n",
        "def PlotFittedValues(model, results, label=''):\n",
        "    \"\"\"Plots original data and fitted values.\n",
        "    model: StatsModel model object\n",
        "    results: StatsModel results object\n",
        "    \"\"\"\n",
        "    years = model.exog[:, 1]\n",
        "    values = model.endog\n",
        "    thinkplot.Scatter(years, values, s=15, label=label)\n",
        "    thinkplot.Plot(years, results.fittedvalues, label='model')\n",
        "\n",
        "\n",
        "def PlotResiduals(model, results):\n",
        "    \"\"\"Plots the residuals of a model.\n",
        "    model: StatsModel model object\n",
        "    results: StatsModel results object    \n",
        "    \"\"\"\n",
        "    years = model.exog[:, 1]\n",
        "    thinkplot.Plot(years, results.resid, linewidth=0.5, alpha=0.5)\n",
        "\n",
        "\n",
        "def PlotResidualPercentiles(model, results, index=1, num_bins=20):\n",
        "    \"\"\"Plots percentiles of the residuals.\n",
        "    model: StatsModel model object\n",
        "    results: StatsModel results object\n",
        "    index: which exogenous variable to use\n",
        "    num_bins: how many bins to divide the x-axis into\n",
        "    \"\"\"\n",
        "    exog = model.exog[:, index]\n",
        "    resid = results.resid.values\n",
        "    df = pandas.DataFrame(dict(exog=exog, resid=resid))\n",
        "\n",
        "    bins = np.linspace(np.min(exog), np.max(exog), num_bins)\n",
        "    indices = np.digitize(exog, bins)\n",
        "    groups = df.groupby(indices)\n",
        "\n",
        "    means = [group.exog.mean() for _, group in groups][1:-1]\n",
        "    cdfs = [thinkstats2.Cdf(group.resid) for _, group in groups][1:-1]\n",
        "\n",
        "    thinkplot.PrePlot(3)\n",
        "    for percent in [75, 50, 25]:\n",
        "        percentiles = [cdf.Percentile(percent) for cdf in cdfs]\n",
        "        label = '%dth' % percent\n",
        "        thinkplot.Plot(means, percentiles, label=label)\n",
        "\n",
        "\n",
        "def SimulateResults(daily, iters=101, func=RunLinearModel):\n",
        "    \"\"\"Run simulations based on resampling residuals.\n",
        "    daily: DataFrame of daily prices\n",
        "    iters: number of simulations\n",
        "    func: function that fits a model to the data\n",
        "    returns: list of result objects\n",
        "    \"\"\"\n",
        "    _, results = func(daily)\n",
        "    fake = daily.copy()\n",
        "    \n",
        "    result_seq = []\n",
        "    for _ in range(iters):\n",
        "        fake.ppg = results.fittedvalues + thinkstats2.Resample(results.resid)\n",
        "        _, fake_results = func(fake)\n",
        "        result_seq.append(fake_results)\n",
        "\n",
        "    return result_seq\n",
        "\n",
        "\n",
        "def SimulateIntervals(daily, iters=101, func=RunLinearModel):\n",
        "    \"\"\"Run simulations based on different subsets of the data.\n",
        "    daily: DataFrame of daily prices\n",
        "    iters: number of simulations\n",
        "    func: function that fits a model to the data\n",
        "    returns: list of result objects\n",
        "    \"\"\"\n",
        "    result_seq = []\n",
        "    starts = np.linspace(0, len(daily), iters).astype(int)\n",
        "\n",
        "    for start in starts[:-2]:\n",
        "        subset = daily[start:]\n",
        "        _, results = func(subset)\n",
        "        fake = subset.copy()\n",
        "\n",
        "        for _ in range(iters):\n",
        "            fake.ppg = (results.fittedvalues + \n",
        "                        thinkstats2.Resample(results.resid))\n",
        "            _, fake_results = func(fake)\n",
        "            result_seq.append(fake_results)\n",
        "\n",
        "    return result_seq\n",
        "\n",
        "\n",
        "def GeneratePredictions(result_seq, years, add_resid=False):\n",
        "    \"\"\"Generates an array of predicted values from a list of model results.\n",
        "    When add_resid is False, predictions represent sampling error only.\n",
        "    When add_resid is True, they also include residual error (which is\n",
        "    more relevant to prediction).\n",
        "    \n",
        "    result_seq: list of model results\n",
        "    years: sequence of times (in years) to make predictions for\n",
        "    add_resid: boolean, whether to add in resampled residuals\n",
        "    returns: sequence of predictions\n",
        "    \"\"\"\n",
        "    n = len(years)\n",
        "    d = dict(Intercept=np.ones(n), years=years, years2=years**2)\n",
        "    predict_df = pandas.DataFrame(d)\n",
        "    \n",
        "    predict_seq = []\n",
        "    for fake_results in result_seq:\n",
        "        predict = fake_results.predict(predict_df)\n",
        "        if add_resid:\n",
        "            predict += thinkstats2.Resample(fake_results.resid, n)\n",
        "        predict_seq.append(predict)\n",
        "\n",
        "    return predict_seq\n",
        "\n",
        "\n",
        "def GenerateSimplePrediction(results, years):\n",
        "    \"\"\"Generates a simple prediction.\n",
        "    results: results object\n",
        "    years: sequence of times (in years) to make predictions for\n",
        "    returns: sequence of predicted values\n",
        "    \"\"\"\n",
        "    n = len(years)\n",
        "    inter = np.ones(n)\n",
        "    d = dict(Intercept=inter, years=years, years2=years**2)\n",
        "    predict_df = pandas.DataFrame(d)\n",
        "    predict = results.predict(predict_df)\n",
        "    return predict\n",
        "\n",
        "\n",
        "def PlotPredictions(daily, years, iters=101, percent=90, func=RunLinearModel):\n",
        "    \"\"\"Plots predictions.\n",
        "    daily: DataFrame of daily prices\n",
        "    years: sequence of times (in years) to make predictions for\n",
        "    iters: number of simulations\n",
        "    percent: what percentile range to show\n",
        "    func: function that fits a model to the data\n",
        "    \"\"\"\n",
        "    result_seq = SimulateResults(daily, iters=iters, func=func)\n",
        "    p = (100 - percent) / 2\n",
        "    percents = p, 100-p\n",
        "\n",
        "    predict_seq = GeneratePredictions(result_seq, years, add_resid=True)\n",
        "    low, high = thinkstats2.PercentileRows(predict_seq, percents)\n",
        "    thinkplot.FillBetween(years, low, high, alpha=0.3, color='gray')\n",
        "\n",
        "    predict_seq = GeneratePredictions(result_seq, years, add_resid=False)\n",
        "    low, high = thinkstats2.PercentileRows(predict_seq, percents)\n",
        "    thinkplot.FillBetween(years, low, high, alpha=0.5, color='gray')\n",
        "\n",
        "\n",
        "def PlotIntervals(daily, years, iters=101, percent=90, func=RunLinearModel):\n",
        "    \"\"\"Plots predictions based on different intervals.\n",
        "    daily: DataFrame of daily prices\n",
        "    years: sequence of times (in years) to make predictions for\n",
        "    iters: number of simulations\n",
        "    percent: what percentile range to show\n",
        "    func: function that fits a model to the data\n",
        "    \"\"\"\n",
        "    result_seq = SimulateIntervals(daily, iters=iters, func=func)\n",
        "    p = (100 - percent) / 2\n",
        "    percents = p, 100-p\n",
        "\n",
        "    predict_seq = GeneratePredictions(result_seq, years, add_resid=True)\n",
        "    low, high = thinkstats2.PercentileRows(predict_seq, percents)\n",
        "    thinkplot.FillBetween(years, low, high, alpha=0.2, color='gray')\n",
        "\n",
        "\n",
        "def Correlate(dailies):\n",
        "    \"\"\"Compute the correlation matrix between prices for difference qualities.\n",
        "    dailies: map from quality to time series of ppg\n",
        "    returns: correlation matrix\n",
        "    \"\"\"\n",
        "    df = pandas.DataFrame()\n",
        "    for name, daily in dailies.items():\n",
        "        df[name] = daily.ppg\n",
        "\n",
        "    return df.corr()\n",
        "        \n",
        "\n",
        "def CorrelateResid(dailies):\n",
        "    \"\"\"Compute the correlation matrix between residuals.\n",
        "    dailies: map from quality to time series of ppg\n",
        "    returns: correlation matrix\n",
        "    \"\"\"\n",
        "    df = pandas.DataFrame()\n",
        "    for name, daily in dailies.items():\n",
        "        _, results = RunLinearModel(daily)\n",
        "        df[name] = results.resid\n",
        "\n",
        "    return df.corr()\n",
        "\n",
        "\n",
        "def TestCorrelateResid(dailies, iters=101):\n",
        "    \"\"\"Tests observed correlations.\n",
        "    dailies: map from quality to time series of ppg\n",
        "    iters: number of simulations\n",
        "    \"\"\"\n",
        "\n",
        "    t = []\n",
        "    names = ['high', 'medium', 'low']\n",
        "    for name in names:\n",
        "        daily = dailies[name]\n",
        "        t.append(SimulateResults(daily, iters=iters))\n",
        "\n",
        "    corr = CorrelateResid(dailies)\n",
        "\n",
        "    arrays = []\n",
        "    for result_seq in zip(*t):\n",
        "        df = pandas.DataFrame()\n",
        "        for name, results in zip(names, result_seq):\n",
        "            df[name] = results.resid\n",
        "\n",
        "        opp_sign = corr * df.corr() < 0\n",
        "        arrays.append((opp_sign.astype(int)))\n",
        "\n",
        "    print(np.sum(arrays))\n",
        "\n",
        "\n",
        "def RunModels(dailies):\n",
        "    \"\"\"Runs linear regression for each group in dailies.\n",
        "    dailies: map from group name to DataFrame\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for daily in dailies.values():\n",
        "        _, results = RunLinearModel(daily)\n",
        "        intercept, slope = results.params\n",
        "        p1, p2 = results.pvalues\n",
        "        r2 = results.rsquared\n",
        "        s = r'%0.3f (%0.2g) & %0.3f (%0.2g) & %0.3f \\\\'\n",
        "        row = s % (intercept, p1, slope, p2, r2)\n",
        "        rows.append(row)\n",
        "\n",
        "    # print results in a LaTeX table\n",
        "    print(r'\\begin{tabular}{|c|c|c|}')\n",
        "    print(r'\\hline')\n",
        "    print(r'intercept & slope & $R^2$ \\\\ \\hline')\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "    print(r'\\hline')\n",
        "    print(r'\\end{tabular}')\n",
        "\n",
        "\n",
        "def FillMissing(daily, span=30):\n",
        "    \"\"\"Fills missing values with an exponentially weighted moving average.\n",
        "    Resulting DataFrame has new columns 'ewma' and 'resid'.\n",
        "    daily: DataFrame of daily prices\n",
        "    span: window size (sort of) passed to ewma\n",
        "    returns: new DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    dates = pandas.date_range(daily.index.min(), daily.index.max())\n",
        "    reindexed = daily.reindex(dates)\n",
        "\n",
        "    ewma = pandas.ewma(reindexed.ppg, span=span)\n",
        "\n",
        "    resid = (reindexed.ppg - ewma).dropna()\n",
        "    fake_data = ewma + thinkstats2.Resample(resid, len(reindexed))\n",
        "    reindexed.ppg.fillna(fake_data, inplace=True)\n",
        "\n",
        "    reindexed['ewma'] = ewma\n",
        "    reindexed['resid'] = reindexed.ppg - ewma\n",
        "    return reindexed\n",
        "\n",
        "\n",
        "def AddWeeklySeasonality(daily):\n",
        "    \"\"\"Adds a weekly pattern.\n",
        "    daily: DataFrame of daily prices\n",
        "    returns: new DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    frisat = (daily.index.dayofweek==4) | (daily.index.dayofweek==5)\n",
        "    fake = daily.copy()\n",
        "    fake.ppg[frisat] += np.random.uniform(0, 2, frisat.sum())\n",
        "    return fake\n",
        "\n",
        "\n",
        "def PrintSerialCorrelations(dailies):\n",
        "    \"\"\"Prints a table of correlations with different lags.\n",
        "    dailies: map from category name to DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    filled_dailies = {}\n",
        "    for name, daily in dailies.items():\n",
        "        filled_dailies[name] = FillMissing(daily, span=30)\n",
        "\n",
        "    # print serial correlations for raw price data\n",
        "    for name, filled in filled_dailies.items():            \n",
        "        corr = thinkstats2.SerialCorr(filled.ppg, lag=1)\n",
        "        print(name, corr)\n",
        "\n",
        "    rows = []\n",
        "    for lag in [1, 7, 30, 365]:\n",
        "        row = [str(lag)]\n",
        "        for name, filled in filled_dailies.items():            \n",
        "            corr = thinkstats2.SerialCorr(filled.resid, lag)\n",
        "            row.append('%.2g' % corr)\n",
        "        rows.append(row)\n",
        "\n",
        "    print(r'\\begin{tabular}{|c|c|c|c|}')\n",
        "    print(r'\\hline')\n",
        "    print(r'lag & high & medium & low \\\\ \\hline')\n",
        "    for row in rows:\n",
        "        print(' & '.join(row) + r' \\\\')\n",
        "    print(r'\\hline')\n",
        "    print(r'\\end{tabular}')\n",
        "\n",
        "    filled = filled_dailies['high']\n",
        "    acf = smtsa.acf(filled.resid, nlags=365, unbiased=True)\n",
        "    print('%0.3f, %0.3f, %0.3f, %0.3f, %0.3f' % \n",
        "          (acf[0], acf[1], acf[7], acf[30], acf[365]))\n",
        "\n",
        "\n",
        "def SimulateAutocorrelation(daily, iters=1001, nlags=40):\n",
        "    \"\"\"Resample residuals, compute autocorrelation, and plot percentiles.\n",
        "    daily: DataFrame\n",
        "    iters: number of simulations to run\n",
        "    nlags: maximum lags to compute autocorrelation\n",
        "    \"\"\"\n",
        "    # run simulations\n",
        "    t = []\n",
        "    for _ in range(iters):\n",
        "        filled = FillMissing(daily, span=30)\n",
        "        resid = thinkstats2.Resample(filled.resid)\n",
        "        acf = smtsa.acf(resid, nlags=nlags, unbiased=True)[1:]\n",
        "        t.append(np.abs(acf))\n",
        "\n",
        "    high = thinkstats2.PercentileRows(t, [97.5])[0]\n",
        "    low = -high\n",
        "    lags = list(range(1, nlags+1))\n",
        "    thinkplot.FillBetween(lags, low, high, alpha=0.2, color='gray')\n",
        "\n",
        "\n",
        "def PlotAutoCorrelation(dailies, nlags=40, add_weekly=False):\n",
        "    \"\"\"Plots autocorrelation functions.\n",
        "    dailies: map from category name to DataFrame of daily prices\n",
        "    nlags: number of lags to compute\n",
        "    add_weekly: boolean, whether to add a simulated weekly pattern\n",
        "    \"\"\"\n",
        "    thinkplot.PrePlot(3)\n",
        "    daily = dailies['high']\n",
        "    SimulateAutocorrelation(daily)\n",
        "\n",
        "    for name, daily in dailies.items():\n",
        "\n",
        "        if add_weekly:\n",
        "            daily = AddWeeklySeasonality(daily)\n",
        "\n",
        "        filled = FillMissing(daily, span=30)\n",
        "\n",
        "        acf = smtsa.acf(filled.resid, nlags=nlags, unbiased=True)\n",
        "        lags = np.arange(len(acf))\n",
        "        thinkplot.Plot(lags[1:], acf[1:], label=name)\n",
        "\n",
        "\n",
        "def MakeAcfPlot(dailies):\n",
        "    \"\"\"Makes a figure showing autocorrelation functions.\n",
        "    dailies: map from category name to DataFrame of daily prices    \n",
        "    \"\"\"\n",
        "    axis = [0, 41, -0.2, 0.2]\n",
        "\n",
        "    thinkplot.PrePlot(cols=2)\n",
        "    PlotAutoCorrelation(dailies, add_weekly=False)\n",
        "    thinkplot.Config(axis=axis, \n",
        "                     loc='lower right',\n",
        "                     ylabel='correlation',\n",
        "                     xlabel='lag (day)')\n",
        "\n",
        "    thinkplot.SubPlot(2)\n",
        "    PlotAutoCorrelation(dailies, add_weekly=True)\n",
        "    thinkplot.Save(root='timeseries9',\n",
        "                   axis=axis,\n",
        "                   loc='lower right',\n",
        "                   xlabel='lag (days)',\n",
        "                   formats=FORMATS)\n",
        "\n",
        "\n",
        "def PlotRollingMean(daily, name):\n",
        "    \"\"\"Plots rolling mean and EWMA.\n",
        "    daily: DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    dates = pandas.date_range(daily.index.min(), daily.index.max())\n",
        "    reindexed = daily.reindex(dates)\n",
        "\n",
        "    thinkplot.PrePlot(cols=2)\n",
        "    thinkplot.Scatter(reindexed.ppg, s=15, alpha=0.1, label=name)\n",
        "    roll_mean = pandas.rolling_mean(reindexed.ppg, 30)\n",
        "    thinkplot.Plot(roll_mean, label='rolling mean')\n",
        "    pyplot.xticks(rotation=30)\n",
        "    thinkplot.Config(ylabel='price per gram ($)')\n",
        "\n",
        "    thinkplot.SubPlot(2)\n",
        "    thinkplot.Scatter(reindexed.ppg, s=15, alpha=0.1, label=name)\n",
        "    ewma = pandas.ewma(reindexed.ppg, span=30)\n",
        "    thinkplot.Plot(ewma, label='EWMA')\n",
        "    pyplot.xticks(rotation=30)\n",
        "    thinkplot.Save(root='timeseries10',\n",
        "                   formats=FORMATS)\n",
        "\n",
        "\n",
        "def PlotFilled(daily, name):\n",
        "    \"\"\"Plots the EWMA and filled data.\n",
        "    daily: DataFrame of daily prices\n",
        "    \"\"\"\n",
        "    filled = FillMissing(daily, span=30)\n",
        "    thinkplot.Scatter(filled.ppg, s=15, alpha=0.3, label=name)\n",
        "    thinkplot.Plot(filled.ewma, label='EWMA', alpha=0.4)\n",
        "    pyplot.xticks(rotation=30)\n",
        "    thinkplot.Save(root='timeseries8',\n",
        "                   ylabel='price per gram ($)',\n",
        "                   formats=FORMATS)\n",
        "    \n",
        "\n",
        "def PlotLinearModel(daily, name):\n",
        "    \"\"\"Plots a linear fit to a sequence of prices, and the residuals.\n",
        "    \n",
        "    daily: DataFrame of daily prices\n",
        "    name: string\n",
        "    \"\"\"\n",
        "    model, results = RunLinearModel(daily)\n",
        "    PlotFittedValues(model, results, label=name)\n",
        "    thinkplot.Save(root='timeseries2',\n",
        "                   title='fitted values',\n",
        "                   xlabel='years',\n",
        "                   xlim=[-0.1, 3.8],\n",
        "                   ylabel='price per gram ($)',\n",
        "                   formats=FORMATS)\n",
        "\n",
        "    PlotResidualPercentiles(model, results)\n",
        "    thinkplot.Save(root='timeseries3',\n",
        "                   title='residuals',\n",
        "                   xlabel='years',\n",
        "                   ylabel='price per gram ($)',\n",
        "                   formats=FORMATS)\n",
        "    \n",
        "    #years = np.linspace(0, 5, 101)\n",
        "    #predict = GenerateSimplePrediction(results, years)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlHruPPe10Rg",
        "outputId": "cfc8d905-c9c4-42a4-863f-920e04638748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "thinkstats2.RandomSeed(18)\n",
        "transactions = ReadData()\n",
        "\n",
        "transactions.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>price</th>\n",
              "      <th>amount</th>\n",
              "      <th>quality</th>\n",
              "      <th>date</th>\n",
              "      <th>ppg</th>\n",
              "      <th>state.name</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Annandale</td>\n",
              "      <td>VA</td>\n",
              "      <td>100</td>\n",
              "      <td>7.075</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>14.13</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>38.830345</td>\n",
              "      <td>-77.213870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Auburn</td>\n",
              "      <td>AL</td>\n",
              "      <td>60</td>\n",
              "      <td>28.300</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>2.12</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>32.578185</td>\n",
              "      <td>-85.472820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Austin</td>\n",
              "      <td>TX</td>\n",
              "      <td>60</td>\n",
              "      <td>28.300</td>\n",
              "      <td>medium</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>2.12</td>\n",
              "      <td>Texas</td>\n",
              "      <td>30.326374</td>\n",
              "      <td>-97.771258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Belleville</td>\n",
              "      <td>IL</td>\n",
              "      <td>400</td>\n",
              "      <td>28.300</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>14.13</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>38.532311</td>\n",
              "      <td>-89.983521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Boone</td>\n",
              "      <td>NC</td>\n",
              "      <td>55</td>\n",
              "      <td>3.540</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>15.54</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>36.217052</td>\n",
              "      <td>-81.687983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         city state  price  amount  ...    ppg      state.name        lat        lon\n",
              "0   Annandale    VA    100   7.075  ...  14.13        Virginia  38.830345 -77.213870\n",
              "1      Auburn    AL     60  28.300  ...   2.12         Alabama  32.578185 -85.472820\n",
              "2      Austin    TX     60  28.300  ...   2.12           Texas  30.326374 -97.771258\n",
              "3  Belleville    IL    400  28.300  ...  14.13        Illinois  38.532311 -89.983521\n",
              "4       Boone    NC     55   3.540  ...  15.54  North Carolina  36.217052 -81.687983\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHfcQqfv2vG9",
        "outputId": "c9e8737f-bd82-44b6-9cd0-93a1d3d1461e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(transactions.shape)\n",
        "transactions.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(147070, 10)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 147070 entries, 0 to 147069\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count   Dtype         \n",
            "---  ------      --------------   -----         \n",
            " 0   city        147070 non-null  object        \n",
            " 1   state       147070 non-null  object        \n",
            " 2   price       147070 non-null  int64         \n",
            " 3   amount      147070 non-null  float64       \n",
            " 4   quality     147070 non-null  object        \n",
            " 5   date        147070 non-null  datetime64[ns]\n",
            " 6   ppg         147070 non-null  float64       \n",
            " 7   state.name  147070 non-null  object        \n",
            " 8   lat         146897 non-null  float64       \n",
            " 9   lon         146897 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
            "memory usage: 11.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYLzRC182Na1",
        "outputId": "70910e7f-9c96-4a15-a8a5-f7bb22b857e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dailies = GroupByQualityAndDay(transactions)\n",
        "for k, v in dailies.items():\n",
        "    print(\"key:\", k, \"\\n value :\", v)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key: high \n",
            " value :                   ppg       date     years\n",
            "date                                      \n",
            "2010-09-02  13.384186 2010-09-02  0.000000\n",
            "2010-09-03  14.459588 2010-09-03  0.002738\n",
            "2010-09-04  14.923333 2010-09-04  0.005476\n",
            "2010-09-05  16.667500 2010-09-05  0.008214\n",
            "2010-09-06  15.537500 2010-09-06  0.010952\n",
            "...               ...        ...       ...\n",
            "2014-05-09  11.468298 2014-05-09  3.682485\n",
            "2014-05-10  10.532326 2014-05-10  3.685223\n",
            "2014-05-11  11.518750 2014-05-11  3.687961\n",
            "2014-05-12  10.578293 2014-05-12  3.690699\n",
            "2014-05-13   9.604615 2014-05-13  3.693437\n",
            "\n",
            "[1241 rows x 3 columns]\n",
            "key: low \n",
            " value :                   ppg       date     years\n",
            "date                                      \n",
            "2010-09-02   4.943750 2010-09-02  0.000000\n",
            "2010-09-03   3.984138 2010-09-03  0.002738\n",
            "2010-09-04   3.530000 2010-09-04  0.005476\n",
            "2010-09-10   4.240000 2010-09-10  0.021903\n",
            "2010-09-14   6.066118 2010-09-14  0.032855\n",
            "...               ...        ...       ...\n",
            "2014-05-09  14.700000 2014-05-09  3.682485\n",
            "2014-05-10  10.332857 2014-05-10  3.685223\n",
            "2014-05-11   3.336667 2014-05-11  3.687961\n",
            "2014-05-12   3.270000 2014-05-12  3.690699\n",
            "2014-05-13   4.447778 2014-05-13  3.693437\n",
            "\n",
            "[1179 rows x 3 columns]\n",
            "key: medium \n",
            " value :                   ppg       date     years\n",
            "date                                      \n",
            "2010-09-02  11.021250 2010-09-02  0.000000\n",
            "2010-09-03   8.055000 2010-09-03  0.002738\n",
            "2010-09-04  16.950000 2010-09-04  0.005476\n",
            "2010-09-05  12.005000 2010-09-05  0.008214\n",
            "2010-09-08  16.250000 2010-09-08  0.016427\n",
            "...               ...        ...       ...\n",
            "2014-05-09   9.037059 2014-05-09  3.682485\n",
            "2014-05-10   9.155686 2014-05-10  3.685223\n",
            "2014-05-11   8.138214 2014-05-11  3.687961\n",
            "2014-05-12   8.959655 2014-05-12  3.690699\n",
            "2014-05-13   9.810625 2014-05-13  3.693437\n",
            "\n",
            "[1238 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPzwDUlI8zdu",
        "outputId": "18dd9af6-1699-44b4-9f4e-3def4ff20058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "PlotDailies(dailies)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/CustomClasses/thinkplot.py:182: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  return plt.subplot(rows, cols, plot_number, **options)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Writing timeseries1.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQdU6Zn82N3p"
      },
      "source": [
        "\n",
        "\n",
        "RunModels(dailies)\n",
        "PrintSerialCorrelations(dailies)\n",
        "MakeAcfPlot(dailies)\n",
        "\n",
        "name = 'high'\n",
        "daily = dailies[name]\n",
        "\n",
        "PlotLinearModel(daily, name)\n",
        "PlotRollingMean(daily, name)\n",
        "PlotFilled(daily, name)\n",
        "\n",
        "years = np.linspace(0, 5, 101)\n",
        "thinkplot.Scatter(daily.years, daily.ppg, alpha=0.1, label=name)\n",
        "PlotPredictions(daily, years)\n",
        "xlim = years[0]-0.1, years[-1]+0.1\n",
        "thinkplot.Save(root='timeseries4',\n",
        "                title='predictions',\n",
        "                xlabel='years',\n",
        "                xlim=xlim,\n",
        "                ylabel='price per gram ($)',\n",
        "                formats=FORMATS)\n",
        "\n",
        "name = 'medium'\n",
        "daily = dailies[name]\n",
        "\n",
        "thinkplot.Scatter(daily.years, daily.ppg, alpha=0.1, label=name)\n",
        "PlotIntervals(daily, years)\n",
        "PlotPredictions(daily, years)\n",
        "xlim = years[0]-0.1, years[-1]+0.1\n",
        "thinkplot.Save(root='timeseries5',\n",
        "                title='predictions',\n",
        "                xlabel='years',\n",
        "                xlim=xlim,\n",
        "                ylabel='price per gram ($)',\n",
        "                formats=FORMATS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqdyIs4r2N8c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8o03KGg2N_-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTeF-dcU1W1V"
      },
      "source": [
        ""
      ]
    }
  ]
}